"""
Little utils script for doing stuff. Call this with function_name, args*
"""

from random import randrange

import torch

from models import *
from training import generate_from_one_input



def gen_metadata( data_fpath, out_fpath, data_size = None ):
    """
    Generates metadata for models working with dataset at given path. `data_size` is used to ignore
    data beyond a certain point in the file. `out_fpath` is the output path.
    """
    # Handle args
    if data_size is not None:
        data_size = int(data_size)

    # Open the text file
    data = open(data_fpath, 'r').read(data_size if data_size is not None else -1)
    data_size = len(data)

    # Get charset
    charset = sorted(list(set(data))) 
    vocab_size = len(charset) 
    print("Data has {0} characters, {1} unique".format(data_size, vocab_size))

    # Char to index and index to char maps
    char_to_ix = { ch:i for i,ch in enumerate(charset) }
    ix_to_char = { i:ch for i,ch in enumerate(charset) }

    # Save 
    sobj = {'data_size'     : data_size,
            'charset'       : charset,
            'vocab_size'    : vocab_size,
            'char_to_ix'    : char_to_ix,
            'ix_to_char'    : ix_to_char
            }
    outf = open(out_fpath, 'w').write(str(sobj))



def torch_2_custom( torch_fpath, custom_fpath, ldim, dmeta_fpath ):
    """
    Converts a TorchLSTM at `torch_fpath` to a CustomLSTM with `ldim`, and saves it's weights
    to `custom_fpath`. `dmeta_fpath` is the path to the metadata file generated by gen_metadata().
    """
    # Arguments
    ldim = int(ldim)

    # Load metadata
    meta = eval(open(dmeta_fpath, 'r').read())
    cnum = meta['vocab_size']
    ix_to_char = meta['ix_to_char']

    # Load TorchLSTM
    tlstm = TorchLSTM(cnum, ldim, 1)
    tlstm.load_model(torch_fpath)
    
    # Create CustomLSTM
    clstm = CustomLSTM(cnum, ldim, init_rand = False)

    # Set up i gate
    clstm.i_gate.weight.data = torch.cat((   tlstm.lstm.weight_hh_l0[          : ldim, :].data,
                                        tlstm.lstm.weight_ih_l0[          : ldim, :].data ), dim = 1)
    clstm.i_gate.bias.data            = tlstm.lstm.bias_hh_l0[            : ldim].data \
                                      + tlstm.lstm.bias_ih_l0[            : ldim].data

    # Set up f gate
    clstm.f_gate.weight.data = torch.cat((   tlstm.lstm.weight_hh_l0[     ldim : 2 * ldim, :].data,
                                        tlstm.lstm.weight_ih_l0[     ldim : 2 * ldim, :].data ), dim = 1)
    clstm.f_gate.bias.data            = tlstm.lstm.bias_hh_l0[       ldim : 2 * ldim].data \
                                      + tlstm.lstm.bias_ih_l0[       ldim : 2 * ldim].data

    # Set up g gate
    clstm.cell_inp.weight.data = torch.cat(( tlstm.lstm.weight_hh_l0[ 2 * ldim : 3 * ldim, :].data,
                                        tlstm.lstm.weight_ih_l0[ 2 * ldim : 3 * ldim, :].data ), dim = 1)
    clstm.cell_inp.bias.data          = tlstm.lstm.bias_hh_l0[   2 * ldim : 3 * ldim].data \
                                      + tlstm.lstm.bias_ih_l0[   2 * ldim : 3 * ldim].data

    # Set up o gate
    clstm.o_gate.weight.data = torch.cat((  tlstm.lstm.weight_hh_l0[  3 * ldim : , :].data,
                                       tlstm.lstm.weight_ih_l0[  3 * ldim : , :].data ), dim = 1)
    clstm.o_gate.bias.data             = tlstm.lstm.bias_hh_l0[  3 * ldim : ].data \
                                       + tlstm.lstm.bias_ih_l0[  3 * ldim : ].data
    
    # Set up decoder
    clstm.decoder.weight.data = tlstm.decoder.weight.data
    clstm.decoder.bias.data = tlstm.decoder.bias.data

    # Print out some data
    stchar = randrange(cnum)
    print("\n\nGenerating for original model")
    gen_data = generate_from_one_input(tlstm, stchar, 200)
    gen_str = ''.join(( ix_to_char[c] for c in gen_data ))
    print("Batch of text generated by original model:\n {0}".format(gen_str))
    print("\n\nGenerating for transferred model")
    gen_data = generate_from_one_input(clstm, stchar, 200)
    gen_str = ''.join(( ix_to_char[c] for c in gen_data ))
    print("Batch of text generated by transferred model:\n {0}".format(gen_str))
    
    # Save model
    clstm.save_model(custom_fpath)
    
    
if __name__ == "__main__":
    
    import sys
    
    args = ', '.join(('"{0}"'.format(a) for a in sys.argv[2:]))
    cmd = "{0}({1})".format(sys.argv[1], args)
    print(cmd)
    eval(cmd)
